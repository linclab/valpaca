{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "understanding-accident",
   "metadata": {},
   "source": [
    "## Extracting data for VaLPACa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moved-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9527d60",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e5f234",
   "metadata": {},
   "source": [
    "**Note:** This example was obtained from [dataset 39 of the Dandi archive](https://dandiarchive.org/dandiset/000039)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILENAME = \"sub-699590236_ses-727153911_behavior+ophys.nwb\" # VisP L2/3\n",
    "FILENAME = \"sub-746926904_ses-764182166_behavior+ophys.nwb\" # RL L2/3\n",
    "FILEPATH = Path(\"nwb_files\", FILENAME)\n",
    "SEED = 10 # for generating the random train/valid split\n",
    "NUM_FR = 60 # number of frames per trial\n",
    "PROP_TRAIN = 0.8 # proportion of the dataset to use for training\n",
    "TRIAL_PARAMS = [\"direction\", \"contrast\"] # trial parameters to record \n",
    "\n",
    "OUTPUT_NAME = \"{}.h5\".format(\"_\".join(FILEPATH.name.split(\"_\")[:2])) # set an output file name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fc216",
   "metadata": {},
   "source": [
    "## Extract data\n",
    "This data file is in the NWB format, and therefore is read using the `pynwb` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd5e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynwb\n",
    "with pynwb.NWBHDF5IO(FILEPATH, \"r\") as io:\n",
    "    read_nwbfile = io.read()\n",
    "    \n",
    "    # extract the stimulus dataframe\n",
    "    stim_df = read_nwbfile.intervals[\"epochs\"].to_dataframe()\n",
    "    stim_df = stim_df.rename(columns={\"start_time\": \"start_frame\", \"stop_time\": \"stop_frame\"})\n",
    "    \n",
    "    # extract full fluorescence data\n",
    "    dff_traces = read_nwbfile.processing[\"brain_observatory_pipeline\"][\"Fluorescence\"][\"DfOverF\"].data[()]\n",
    "\n",
    "    # extract the full timestamps\n",
    "    timestamps = read_nwbfile.processing[\"brain_observatory_pipeline\"][\"Fluorescence\"][\"DfOverF\"].timestamps[()]\n",
    "    \n",
    "    # ignore the length warning for the MotionCorrection time series - it is not relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c690fe17",
   "metadata": {},
   "source": [
    "<hr style=\"border:1.5px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fad534",
   "metadata": {},
   "source": [
    "## Format data\n",
    "\n",
    "### If `stim_df`, `dff` and `timestamps` are properly specified, the rest should work on its own (unless additional exclusion criteria are needed: see below):\n",
    "- `stim_df`: Stimulus dataframe, where each row carries information for a single trial: \n",
    "  - `start_frame`,\n",
    "  - `stop_frame`, \n",
    "  - the info specified by `TRIAL_PARAMS`. \n",
    "- `dff_traces`: dF/F per frame, into which `stim_df['start_frame']` and `stim_df['stop_frame']` index.   \n",
    "- `timestamps`: Timestamp for each dF/F frame (in sec).  \n",
    "\n",
    "### Exclusion criteria:\n",
    "- NaN under any of the necessary `stim_df` columns.\n",
    "- Trial length shorter than 80% of `NUM_FR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e032e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(num_sec):\n",
    "    num_min = int(num_sec // 60)\n",
    "    num_sec = num_sec - num_min * 60\n",
    "    return num_min, num_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdb8678",
   "metadata": {},
   "source": [
    "### Check for potential problems in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a734ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dff_traces)!= len(timestamps):\n",
    "    raise ValueError(\"'dff_traces' and 'timestamps' should have the same length.\")\n",
    "\n",
    "check_cols = [\"start_frame\", \"stop_frame\"] + TRIAL_PARAMS\n",
    "for col in check_cols:\n",
    "    if col not in stim_df.columns:\n",
    "        raise KeyError(f\"'stim_df' missing '{col}' column.\")\n",
    "\n",
    "if stim_df[\"start_frame\"].min() < 0:\n",
    "    raise ValueError(\"Lowest start frame cannot be below 0.\")\n",
    "\n",
    "if stim_df[\"stop_frame\"].max() > len(dff_traces):\n",
    "    raise ValueError(\"Highest stop frame cannot be greater than the length of 'dff_traces'.\")\n",
    "\n",
    "if (stim_df[\"stop_frame\"] - stim_df[\"start_frame\"]).min() < 0:\n",
    "    raise ValueError(\"No stop frame should be smaller than its corresponding start frame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb9e9e1",
   "metadata": {},
   "source": [
    "### Compute relevant info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8d2dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-6d8dce54b772>:11: UserWarning: Excluding 24 trials (2.04%).\n",
      "  warnings.warn(f\"Excluding {num_excl} trials ({prop_excl}%).\")\n"
     ]
    }
   ],
   "source": [
    "# compute dt\n",
    "dt = np.diff(timestamps).mean()\n",
    "\n",
    "# exclude trials, if applicable, and warn\n",
    "excl_nan = np.isnan(sum([stim_df[param] for param in [\"start_frame\", \"stop_frame\"] + TRIAL_PARAMS]))\n",
    "excl_leng = (stim_df[\"stop_frame\"] - stim_df[\"start_frame\"]) < 0.8 * NUM_FR\n",
    "excl = excl_nan + excl_leng\n",
    "num_excl = sum(excl.astype(bool))\n",
    "if num_excl:\n",
    "    prop_excl = np.around(100 * num_excl / len(excl), 2)\n",
    "    warnings.warn(f\"Excluding {num_excl} trials ({prop_excl}%).\")\n",
    "stim_df_keep = stim_df.loc[~excl]\n",
    "\n",
    "# aggregate trial parameter data\n",
    "trial_param_data = dict()\n",
    "for trial_param in TRIAL_PARAMS:\n",
    "    trial_param_data[trial_param] = stim_df_keep[trial_param].to_numpy()\n",
    "\n",
    "# get start and stop frames\n",
    "start_fr = stim_df_keep[\"start_frame\"].to_numpy().astype(int)\n",
    "stop_fr = stim_df_keep[\"stop_frame\"].to_numpy().astype(int)\n",
    "num_fr = stop_fr - start_fr\n",
    "num_trials = len(start_fr)\n",
    "\n",
    "# check number of frames per trial\n",
    "if NUM_FR < num_fr.min():\n",
    "    warnings.warn(\"The number of frames per trial is lower than the minimum number of frames per trial.\")\n",
    "if NUM_FR > num_fr.max():\n",
    "    warnings.warn(\"The number of frames per trial is higher than the maximum number of frames per trial.\")\n",
    "if NUM_FR > num_fr.min() * 1.1:\n",
    "    warnings.warn(\"The number of frames per trial is higher by at least 10% than the minimum number of frames per trial.\")\n",
    "\n",
    "# get the number of train/valid trials\n",
    "num_train = int(num_trials * PROP_TRAIN)\n",
    "num_valid = num_trials - num_train\n",
    "\n",
    "# calculate the duration of each trial, on average\n",
    "durations = timestamps[stop_fr] - timestamps[start_fr]\n",
    "sec_per_trial = durations.mean()\n",
    "duration_min, duration_sec = get_duration(durations.sum())\n",
    "\n",
    "# extract dF/F data\n",
    "index = (start_fr + np.arange(NUM_FR).reshape(-1, 1)).T\n",
    "dff = dff_traces[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7c96f",
   "metadata": {},
   "source": [
    "### Report a few characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7d24d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total : 1152 trials (38m 07.05s)\n",
      "Per   : 59 to 61 frames (1.9853s)\n",
      "dt    : 0.0332 sec / frame\n",
      "Split : 921 train / 231 valid\n",
      "\n",
      "Overall: 1152 trials x 60 frames x 72 ROIs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total : {num_trials} trials ({duration_min}m {duration_sec:05.2f}s)\")\n",
    "print(f\"Per   : {num_fr.min()} to {num_fr.max()} frames ({sec_per_trial:.4f}s)\")\n",
    "print(f\"dt    : {dt:.4f} sec / frame\")\n",
    "print(f\"Split : {num_train} train / {num_valid} valid\")\n",
    "print(\"\\nOverall: {} trials x {} frames x {} ROIs\".format(*dff.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-italy",
   "metadata": {},
   "source": [
    "### List of keys to include in the output h5 file\n",
    "`dt` (1 value)  \n",
    "`train_fluor` (trial x ROI)  \n",
    "`train_idx` (trial numbers)  \n",
    "`train_{param}` (value per trial) (param of interest)  \n",
    "`valid_fluor` (trial x ROI)  \n",
    "`valid_idx` (trial numbers)  \n",
    "`valid_{param}` (value per trial) (param of interest)  \n",
    "\n",
    "### Keys that will be added during preprocessing with OASIS\n",
    "*`obs_bias_init` (a 0 per ROI)  \n",
    "*`obs_gain_init` (a value per ROI)   \n",
    "*`obs_tau_init` (a value per ROI)   \n",
    "*`obs_var_init` (a value per ROI)  \n",
    "*`train_ocalcium` (trial x ROI)  \n",
    "*`train_ospikes` (trial x ROI)  \n",
    "*`valid_ocalcium` (trial x ROI)  \n",
    "*`valid_ospikes` (trial x ROI)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36359a12",
   "metadata": {},
   "source": [
    "### Add dt (sec / frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48eced3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"dt\": dt,    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37cace9",
   "metadata": {},
   "source": [
    "### Select and add training/validation indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ccd902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "randst = np.random.RandomState(SEED)\n",
    "\n",
    "train_idxs = randst.choice(num_trials, num_train, replace=False)\n",
    "valid_mask = np.zeros(num_trials).astype(bool)\n",
    "valid_mask[train_idxs] = True\n",
    "valid_idxs = np.where(~valid_mask)[0]\n",
    "randst.shuffle(valid_idxs)\n",
    "\n",
    "data_dict[f\"train_idx\"] = train_idxs\n",
    "data_dict[f\"valid_idx\"] = valid_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b1bfaf",
   "metadata": {},
   "source": [
    "### Add trial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8a5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in [\"train\", \"valid\"]:\n",
    "    idxs = data_dict[f\"{prefix}_idx\"]\n",
    "    for key, vals in trial_param_data.items():\n",
    "        data_dict[f\"{prefix}_{key}\"] = vals[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd183a5",
   "metadata": {},
   "source": [
    "### Add fluorescence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "artificial-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in [\"train\", \"valid\"]:\n",
    "    idxs = data_dict[f\"{prefix}_idx\"]\n",
    "    data_dict[f\"{prefix}_fluor\"] = dff[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c20a08",
   "metadata": {},
   "source": [
    "### Save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "operational-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(OUTPUT_NAME, \"w\") as f:\n",
    "    for key, value in data_dict.items():\n",
    "        f.create_dataset(key, data=value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ca742",
   "metadata": {},
   "source": [
    "### Create file with added OASIS-inferred spiking data, and initialization values\n",
    "Took 20 min locally, for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ead1c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "run_file = Path(\"..\", \"utils\", \"preprocessing_oasis.py\")\n",
    "os.environ[\"RUN_FILE\"] = str(run_file)\n",
    "os.environ[\"DATA_FILE\"] = str(OUTPUT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae2d4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ../utils/preprocessing_oasis.py --data_path sub-746926904_ses-764182166.h5 --normalize --undo_train_test_split\n",
      "/home/colleen/miniconda3/envs/ssl/lib/python3.9/site-packages/scipy/signal/_spectral_py.py:1999: UserWarning: nperseg = 256 is greater than input length  = 61, using nperseg = 61\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/home/colleen/miniconda3/envs/ssl/lib/python3.9/site-packages/numpy/lib/function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/colleen/miniconda3/envs/ssl/lib/python3.9/site-packages/numpy/lib/function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "!echo \"python ${RUN_FILE} --data_path ${DATA_FILE} --normalize --undo_train_test_split\"\n",
    "!python ${RUN_FILE} --data_path ${DATA_FILE} --normalize --undo_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665edbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
